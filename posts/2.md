# Write-Ahead Logging and Transactions

In our last post we came within inches of satisfying three use-cases for a banking application:

- [x] Our first iteration must support opening accounts, depositing funds, withdrawing funds, and transfering funds between accounts,
- [x] Accounts are identified by the customer's first name and, for now, are guaranteed to be unique. Accounts have a balance, and the balance is always an integer
- [ ] Power loss is frequent so we must be able to handle intermittent failures gracefully. Data should be retainted across startups/shutdowns, even if they're unexpected

A very specific unhappy-path event where the power fails in the middle of a funds transfer kept us from meeting our last use-case criteria. In this post we'll start implementing a powerful algorithm used in modern database systems called AIRES[^1] which will help us guarantee that failure during compound operations like a funds transfer will never lead to inconsistent or invalid data being written to durable storage.

[^1]: Cite the AIRES paper here and spell out the acronym

As written, our database implementation currently focuses on recording the outcome of operations. Each time a deposit is made, we update the relevant account balance. Similarly, we update an account balance after a withdrawal. What we seem to be most interested in the current state of affairs - a list of accounts and current balances are the minimum we need to meet our use cases.  

This is analagous to asking *"Who won?"* after a sports game. But that's rarely the most interesting part of a game - it's the sequence of events that led to the outcome that really capture our attention! Capturing the sequence of events lets us answer the questions *"What happened?"* **and** *"Who won?"*

As it turns out capturing events in addition to outcomes can have big implications. Let's set up an event logging system and see how it can help us fix our outstanding compound operation problem.

## Implementing Logging

First we'll write a `Log` class that whose interface will let us create log entries that correspond to modifications we make to data in the `Buffer`:

```ruby
class Log
  FILENAME = "log.txt"

  def initialize
    File.open(FILENAME, "a") {}
  end

  def create(account_name)
    log do
      "create|#{account_name}"
    end
  end

  def update(account_name, old_value, new_value)
    log do
      "update|#{account_name},#{old_value},#{new_value}"
    end
  end

  private

  def log
    File.open(FILENAME, "a") do |file|
      file.puts yield
    end
  end
end
```

`Log`'s public interface is pretty closely tied to `Buffer`'s. It provides a mechanism for logging `Buffer` operations that modify data in-memory (at least, the ones we've implemented so far!) Each entry specifies the type of operation along with some operation-specific data that describe what changed, and how it changed.

To start using `Log`, we can set it up in the `Bank` initializer and make calls during banking operations:

```ruby
# ...
require_relative "log"
# ...

class Bank
  def initialize
    # ...
    @log = Log.new
  end

  def open_account(account_name)
    @log.create(account_name)
    @buffer.create(account_name)
  end

  # ...

  def deposit(account_name, amount)
    # ...
    @log.update(account_name, balance, new_balance)
    @buffer.update(account_name, new_balance)
  end

  def withdraw(account_name, amount)
    # ...
    @log.update(account_name, balance, new_balance)
    @buffer.update(account_name, new_balance)
  end

  # ...
end
```

This type of logging is called **W**rite-**A**head **L**ogging (WAL) because we log how we intend to change data ahead of time.  The fact that logging these events before making any changes in-memory will prove to be a very important point. Similar to how you change the scoreboard only after an scoring *event* takes place, we'll record the *event* before we change the buffer to reflect the outcome of the event. We'll always write ahead-of-time, before changing the data.

We can see now that our log captures a sequence of events that happened, while our data file accurately captures the final outcomes:

```irb
[outcome]
```

On it's own, the WAL hasn't done much to solve our problem with compound operations being inadvertently interrupted. Try simulating the bug again and notice that the log simply reports what's happened, but doesn't provide any information about what *hasn't* happened.

## Transaction Logging

What we want is to indicate in our log of events that a chunk of log entries should be considered atomic, indivisible, and uninterruptable.  This is often described as a series of events either all completing or all failing and nothing inbetween. In database systems this is called a **transaction**. In our WAL we can make a special log entry to indicate that everything following should be considered a single, atomic operation. Then when we've finished the operation we can log that the transaction has *committed*

To implement transactions we'll set up a mechanism to transparently take care of that logging   What I'm aiming for is an interface like this that we could implement in `Bank#transfer`:

```ruby
class Bank
  def transfer(src_account_name, dest_account_name, amount)
    # Proposed transaction API
    transaction do
      deposit(src_account_name, amount)
      withdraw(dest_account_name, -amount)
    end
  end
```

I'll set up a `TransactionManager` class that implements a `#transaction` method.  The class will take an instance of `Log` so that it can handle *transaction start* and *transaction commmit* entries:

```ruby
class TransactionManager
  def initialize(log)
    @log = log
  end

  def transaction
    return unless block_given?

    @log.transaction_start
    yield
    @log.transaction_commit
  end
end
```

Our `Log` now needs to support these new types of log entries:

```ruby
class Log
  # ...

  def transaction_start
    log { "trx_start" }
  end

  def transaction_commit
    log { "trx_commit" }
  end

  # ...
end
```

The `Bank` initializer can take care of setting up transaction management, and we can wrap the body of the `#transfer` method in a transaction:

```ruby
# ...
require_relative "transaction_manager"

class Bank
  def initialize
    # ...
    @log = Log.new
    @trx = TransactionManager.new(@log)
  end

  # ...

  def transfer(src_account_name, dest_account_name, amount)
    @trx.transaction do
      deposit(src_account_name, amount)
      withdraw(dest_account_name, -amount)
    end
  end

  # ...
end
```

It's a little more verbose[^2] than the interface I proposed above, but it'll do! We can now see that WAL entries involving a transfer are wrapped in start and commit messages - giving us clues as to whether all parts of an atomic operation were successful (as evidenced by a commit message) or not.

[^2]: I bet you can whip up some syntactic sugar to make it cleaner!

## Analyzing the WAL
TODO: Cover detecting failure scenario and start of entries to undo by parting WAL and populating two variables

## Undoing Uncommited Changes
TODO: Cover undoing uncomitted changes, flushing to disk, and writing a rollback entry

## Big Ideas: Events, Mutability, and Sources of Truth
TBD

## The Bug, Revisited
TODO: Recap the issue and how our changes address it. Point out the algorithm for operations: ALWAYS log first, ALWAYS modify in-memory second, ALWAYS persist to durable storage third.

## Performance Concerns on the Horizon?
TODO: Allude to performance issues that would prompt us to use an async persistence strategy
